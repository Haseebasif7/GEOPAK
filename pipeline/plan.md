# üáµüá∞ GEOPAK-V3

**Province-Aware Hierarchical Mixture Geolocation Network**

**Task:**
Image ‚Üí Latitude, Longitude
**Scope:** Pakistan only
**Inputs at inference:** RGB image only
**Labels available at training:** lat, lon, province

---

# 0Ô∏è‚É£ Core Design Philosophy (Read This Once)

This model is built on **five principles**:

1. **Hierarchy beats regression**
2. **Geography must be learned before vision is fine-tuned**
3. **Uncertainty must be modeled, not ignored**
4. **Rare regions must be protected from collapse**
5. **Offsets should never fight classification**

Everything below follows from these principles.

---

# 1Ô∏è‚É£ Dataset & Preprocessing (MANDATORY)

## 1.1 Dataset Schema

Each sample:

```json
{
  "id": string,
  "image": RGB image,
  "latitude": float,
  "longitude": float,
  "province": one of [
    Sindh,
    Punjab,
    Khyber Pakhtunkhwa,
    Islamabad Capital Territory,
    Gilgit-Baltistan,
    Balochistan,
    Azad Kashmir
  ]
}
```

======================================================================
Province distribution (for rows WITH province):
======================================================================
  Sindh: 89,252 (69.41%)
  Punjab: 24,645 (19.17%)
  Khyber Pakhtunkhwa: 5,881 (4.57%)
  Islamabad Capital Territory: 4,841 (3.76%)
  Gilgit-Baltistan: 3,125 (2.43%)
  Balochistan: 550 (0.43%)
  Azad Kashmir: 297 (0.23%)

---

## 1.2 Province-Aware Geocell Construction (OFFLINE STEP)

### Step 1 ‚Äî Split by Province

Process **each province independently**.

### Step 2 ‚Äî Coordinate Projection

Convert lat/lon ‚Üí meters (UTM).

### Step 3 ‚Äî Clustering

Use **HDBSCAN** (preferred) or **K-Means** per province.

Constraints:

* Min samples per cell: **40**

* Merge undersized clusters.

### Step 4 ‚Äî Save Metadata

For every cell:

```json
{
  "cell_id": int,
  "province_id": int,
  "center_lat",
  "center_lon",
  "radius_km",
  "neighbor_cell_ids"
}
```

---

## 1.3 Final Training Sample Fields

Each image now has:

```
image
province_id
cell_id
cell_center_latlon
```

---

# 2Ô∏è‚É£ Model Architecture (FULL SPEC)

---

## 2.1 Dual-Encoder Architecture (Complementary Representation Learning)

### Why Dual-Encoder Works

The model faces two different image regimes:

* **Scenery-rich images** ‚Üí roads, mountains, skylines, landscapes ‚Üí strong spatial cues
* **Scenery-poor images** ‚Üí people, shops, objects, partial views ‚Üí weak but contextual cues

üëâ No single encoder is optimal for both.

**Solution:** Split responsibilities with complementary encoders.

| Encoder | Role |
|---------|------|
| **CLIP** | Robust general context, culture, objects, ambiguity handling |
| **Scene Encoder** | Strong geometry, layout, environment structure |

This is **complementary representation learning**, not redundancy.

---

### 2.1.1 Encoder A ‚Äî CLIP (Primary, Robust)

**ViT-B/16 (CLIP-pretrained)**

* Input: `3 √ó 224 √ó 224`
* Output: `D = 768`
* Initial state: **fully frozen**
* Handles all images safely

---

### 2.1.2 Encoder B ‚Äî Scene Encoder (Specialist)

Choose **ONE** of the following:

* **ResNet-50 (Places365-pretrained)**
* **ConvNeXt-Tiny (Places365-pretrained)**
* **ViT-Small (Places or ImageNet-Places hybrid)**

* Output: typically `512` or `768`
* ‚ö†Ô∏è This encoder is **not trusted blindly** ‚Äî it's a specialist that helps when scenery is informative

---

## 2.2 Projection Before Fusion (CRITICAL)

**Never fuse raw encoder outputs directly.**

**Why?**
* Feature scales differ
* Semantics differ
* One encoder will dominate

**Correct approach:**

```
CLIP_feat (768)
‚Üì
Linear(768 ‚Üí 512)
LayerNorm
GELU
‚Üí E_clip (512)

Scene_feat (512/768)
‚Üì
Linear(‚Üí 512)
LayerNorm
GELU
‚Üí E_scene (512)
```

Now both live in **compatible geometry space** (512-dim).

---

## 2.3 Fusion Strategy

### ‚ùå What NOT to do

* Simple concatenation only
* Simple averaging
* Letting scene encoder dominate early

### ‚úÖ Correct Fusion (Recommended)

**Option 1 ‚Äî Gated Fusion (BEST)**

```
Œ± = sigmoid( Linear([E_clip, E_scene]) )
E_fused = Œ± ¬∑ E_scene + (1 ‚àí Œ±) ¬∑ E_clip
```

**Interpretation:**
* If scenery is informative ‚Üí trust scene encoder (Œ± ‚Üí 1)
* If image is ambiguous ‚Üí fall back to CLIP (Œ± ‚Üí 0)
* This is **learned trust calibration**

**Option 2 ‚Äî Residual Fusion (Simpler, still good)**

```
E_fused = E_clip + Œ≤ ¬∑ E_scene
```

Where Œ≤ is:
* Small (e.g., initialized to 0.1)
* Learnable

CLIP stays dominant unless scene signal is strong.

---

## 2.4 Complete Feature Flow

```
Image (3 √ó 224 √ó 224)
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CLIP Encoder    ‚îÇ Scene Encoder   ‚îÇ
‚îÇ (frozen)        ‚îÇ (frozen)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                ‚îÇ
         ‚Üì                ‚Üì
    CLIP_feat (768)  Scene_feat (512/768)
         ‚îÇ                ‚îÇ
         ‚Üì                ‚Üì
    Proj ‚Üí E_clip    Proj ‚Üí E_scene
         ‚îÇ                ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚Üì
           Fusion Module
                  ‚Üì
            E_img (512)
```

üëâ **Everything else stays exactly the same** ‚Äî province head, cell heads, offsets, losses ‚Äî unchanged.

---

# 3Ô∏è‚É£ Head 0 ‚Äî Province Classification (Top-Level Gate)

### Architecture

```
E_img (512)
‚Üì
Linear(512 ‚Üí 256)
LayerNorm
GELU
‚Üì
Linear(256 ‚Üí 7)
Softmax
```

### Loss

**Weighted Cross-Entropy with Effective-Number Weighting**

#### 3.1 Class Weights (Concrete Values)

Use **effective-number weighting**, not raw inverse frequency.

**Step-by-Step Formula:**

1. **Effective number** (per province):
   ```
   E_p = (1 ‚àí Œ≤^n_p) / (1 ‚àí Œ≤)
   ```

2. **Weight** (inverse of effective number):
   ```
   w_p = 1 / E_p
   ```

3. **Normalize by mean** (critical step):
   ```
   w_p_normalized = w_p / mean(w_p)
   ```

Where:
* `Œ≤ = 0.9995` (smoothing factor)
* `n_p` = number of samples in province `p`

**Why this works:**
* Avoids exploding weights for rare provinces (AJK, Balochistan)
* More stable than raw inverse frequency
* Better generalization for imbalanced classes
* Normalization ensures weights are on a reasonable scale

**Implementation:**

```python
beta = 0.999
# Step 1: Calculate effective number per province
effective_num = (1 - beta ** n_per_province) / (1 - beta)
# Step 2: Weight is inverse of effective number
weights = 1.0 / effective_num
# Step 3: Normalize by mean (CRITICAL)
weights = weights / weights.mean()
```

---

# 4Ô∏è‚É£ Head 1 ‚Äî Province-Gated Geocell Classification

### Design Rule

üëâ **NO single Pakistan-wide classifier**

### Implementation

* One classifier **per province**
* Each classifier only sees its province‚Äôs cells

Example (Sindh):

```
Linear(512 ‚Üí 512)
LayerNorm
GELU
‚Üì
Linear(512 ‚Üí N_cells_sindh)
Softmax
```

### Training

* Use **only the ground-truth province head**
* Ignore others

---

## 4.1 Distance-Aware Label Smoothing (Inside Province Only)

For true cell `c`:

```
y_i = exp( -dist_km(c, i) / œÑ )
```
TAU_BY_PROVINCE = {
    "ICT": 10.0,
    "Sindh": 30.0,
    "Punjab": 60.0,
    "Khyber Pakhtunkhwa": 50.0,
    "Azad Kashmir": 40.0,
    "Gilgit-Baltistan": 100.0,
    "Balochistan": 100.0,
}

tau = TAU_BY_PROVINCE[province]
y_i = exp(-distance_km(true_cell, i) / tau)
y = y / y.sum()

* Apply only to neighbor cells
* Renormalize

### Loss

```
L_cell = KLDiv(y_soft || p_pred)
```

---

# 5Ô∏è‚É£ Cell & Province Embeddings

### Embeddings

```
CellEmbedding: (N_cells_total, 64)
ProvinceEmbedding: (7, 16)
```

These are **learned parameters**.

---

# 6Ô∏è‚É£ Head 2 ‚Äî Cell-Aware Offset Refinement (Critical Precision Head)

### Input (Concatenated)

```
[E_img (512),
 CellEmbedding (64),
 ProvinceEmbedding (16)]
‚Üí 592 dims
```

### MLP (WITH RESIDUALS)

```
Linear(592 ‚Üí 256)
LayerNorm
GELU
‚Üì
Linear(256 ‚Üí 256)
LayerNorm
‚Üì
Residual
‚Üì
Linear(256 ‚Üí 128)
GELU
‚Üì
Linear(128 ‚Üí 2) ‚Üí Œîlat, Œîlon
```

### Constraints

* Clamp offsets to:

```
¬± cell_radius √ó province_scale
```

Province scale:

* Punjab / ICT: 0.6
* Sindh / KPK: 1.0
* GB / Balochistan: 1.4

---

# 7Ô∏è‚É£ Head 3 ‚Äî Auxiliary Coarse Regression (TRAINING ONLY)

```
E_img
‚Üì
Linear(512 ‚Üí 256)
GELU
‚Üì
Linear(256 ‚Üí 2) ‚Üí lat, lon
```

Used only to stabilize training.

---

# 8Ô∏è‚É£ Inference Logic (Mixture of Hypotheses)

1. Predict province probabilities
2. Select **Top-2 provinces**
3. For each province:

   * Select **Top-K = 5 cells**
4. For each cell:

   ```
   pred_i = cell_center + offset_i
   ```
5. Final output:

``` 
p_i‚Äã=P(province p‚Äã‚à£image) √ó P(cell c‚Äã‚à£image,province p‚Äã)

LatLon = Œ£ p_i √ó pred_i
```

This is **not argmax**. This is critical.

---

# 9Ô∏è‚É£ Loss Functions (Exact)

### 9.1 Province Loss

```
L_province = Weighted Cross-Entropy
```

### 9.2 Geocell Loss

```
L_cell = KLDiv
```

### 9.3 Offset Loss

```
L_offset = Œ£ p_i √ó Haversine(pred_i, GT)
```

### 9.4 Auxiliary Loss

```
L_aux = Haversine(aux_pred, GT)
```

---

## 9.5 Total Loss

```
L_total =
  0.5 √ó L_province
+ 1.0 √ó L_cell
+ 1.0 √ó L_offset
+ 0.1 √ó L_aux
```

---

# üîü Training Pipeline (STRICTLY FOLLOW)

---

## Phase 0 ‚Äî Province Warm-Up (VERY IMPORTANT)

* **CLIP Encoder**: ‚ùå Frozen
* **Scene Encoder**: ‚ùå Frozen
* Train: Province head only
* **Fusion gate learns when scene helps**
* Epochs: 5‚Äì8
* Target: >95% accuracy

**Why freeze both?**
* You want calibration, not feature drift
* Fusion gate learns trust without encoder updates

---

## Phase 1 ‚Äî Geography Structure Learning

* **CLIP Encoder**: ‚ùå Frozen
* **Scene Encoder**: ‚ùå Frozen
* Train:

  * Province head
  * Province geocell heads
  * Offset heads
  * Embeddings
  * **Fusion gate**
* Epochs: 25‚Äì30
* LR: 1e-3

**Now the model learns:**
* "Scene features help here, but not there"
* Geographic structure without encoder drift

---

## Phase 2 ‚Äî Partial Vision Adaptation (VERY CAREFUL)

* Unfreeze:
  * Top **30%** of CLIP encoder
  * Top **20%** of Scene encoder
* LR:

  * CLIP: 1e-5
  * Scene: 5e-6 (smaller ‚Äî more brittle and shortcut-prone)
  * Heads: 5e-4
* Epochs: 30‚Äì40
* **Province-balanced batches**

**Why smaller LR for scene encoder?**
* It is more brittle and shortcut-prone
* Conservative updates prevent overfitting to scene shortcuts

---

## Phase 3 ‚Äî Optional Full Fine-Tune

* Only if validation improves (especially on indoor/object subset)
* CLIP Encoder LR: 5e-6
* Scene Encoder LR: 2e-6 (even more conservative)
* Heads LR: 1e-4

---

# 1Ô∏è‚É£1Ô∏è‚É£ Batch Sampling (MANDATORY)

Each batch:

* Equal samples per province
* Oversample rare provinces
* Strong augmentation only for Sindh/Punjab

Without this, you **will not win**.

---

# 1Ô∏è‚É£2Ô∏è‚É£ Data Augmentation (Geography-Safe)

‚úÖ Allowed:

* Random resized crop
* Color jitter
* Weather simulation
* Mild blur / noise
* Seasonal color shift

‚ùå Forbidden:

* Horizontal flip
* Large rotations
* Perspective warp

---

# 1Ô∏è‚É£3Ô∏è‚É£ Evaluation Metrics (ONLY THESE)

Report:

* Median error (km)
* 90th percentile error
* Accuracy @ 1km / 5km / 25km
* Per-province breakdown
* Urban vs rural

---

# üèÜ Final Guarantee (Honest)

If:

* Your labels are clean
* Geocells are well built
* Batches are balanced
* You follow this strictly

üëâ **No global model will beat this inside Pakistan.**
üëâ **No regression-only model will come close.**

---

